---
title: "High-dimensional and universally consistent k-sample tests"
authors: "<strong>Sambit Panda</strong>*, Cencheng Shen*, Ronan Perry, Jelle Zorn, Antoine Lutz, Carey E. Priebe, and Joshua T. Vogelstein"
journal: arXiv
doi: "10.48550/arXiv.1910.08883"
abstract: |
  The k-sample testing problem involves determining whether k groups of data points are each drawn from the same distribution. The standard method for k-sample testing in biomedicine is Multivariate analysis of variance (MANOVA), despite that it depends on strong, and often unsuitable, parametric assumptions. Moreover, independence testing and k-sample testing are closely related, and several universally consistent high-dimensional independence tests such as distance correlation (Dcorr) and Hilbert-Schmidt-Independence-Criterion (Hsic) enjoy solid theoretical and empirical properties. In this paper, we prove that independence tests achieve universally consistent k-sample testing and that k-sample statistics such as Energy and Maximum Mean Discrepancy (MMD) are precisely equivalent to Dcorr. An empirical evaluation of nonparametric independence tests showed that they generally perform better than the popular MANOVA test, even in Gaussian distributed scenarios. The evaluation included several popular independence statistics and covered a comprehensive set of simulations. Additionally, the testing approach was extended to perform multiway and multilevel tests, which were demonstrated in a simulated study as well as a real-world fMRI brain scans with a set of attributes.
links:
  - "Code: https://hyppo.neurodata.io/api/generated/hyppo.ksample.ksample#hyppo.ksample.KSample"
  - "Poster: ../pdf/2021-hyppo-brain.pdf"
  - "Talk: ../pdf/2021-hyppo-gyss.pdf"
type: preprint
date: 2023-10-11
featured: true
equalContribution: true
intro: Introduces the idea that the k-sample testing problem and independence testing problem are equivalent up to a transformation of the data.
tags:
  - Hypothesis Testing
---
